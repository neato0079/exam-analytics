To do:
- Create mock .csv of exam data
- pass .csv from cli to Django app to be parsed
- figure out what data structure will be created from the csv to be used by frontend graphing app
- 
...

django will take a csv supplied by the user
csv will be converted to a data structure
data will be passed to frontend to generated a graph to be displayed in the browser

csv should be organized as such:
Exam Complete Date/Tm,    Order Procedure Accession,  Exam Order Date/Time,   Final Date/Tm,   Exam Order Name   

notes:

Once the app is in a presentable state, use PyInstaller to package the project into an exe. Be sure to configure PyInstaller to start the Django server and then open up the browser to localhost:8000 when the exe is ran. 

Also do error handling for if port 8000 is not free

maybe make a data class

csv
	- filters
		- by date
			- year
			- month
			- day
			- weekend
		- by modality
		- by shift
		

		- order priority
		- ordering physician
		- TAT

11/21:

Currently, the user uploaded csv is stored in a django session. This should be fine for development but look into other ways to store that data for production. A session isn't meant for large files so it will cause preformance problems during production.

maybe set up a db or have the app save the csv on disk and just read from there

11/26:

when the user uploads the csv, it gets converted to json. but why. keep it csv for now.

user uploads csv to django server
server saves csv in a session (change this later. see 11/21 note)
server then redirects to results view
results view reads the csv stored in session and generates a graph
then the view renders an html page with the generated graph

12/6:

in helpers.py, in apply_filt(), the original logic depended on a certain type of date/time format. this format changed after implementing a csv -> JSON conversion in order to store in dj sessions. idk format it is now or how it changes that function but look into it dweeb

12/13:

FOCUS MODE BEUCASE EOY IS CLOSE WTF

SHORT TERM GOAL(12/13):

Get app to the following functionality:
- Allow user to upload csv of exam analytics from RIS
- Store csv data as JSON in django session
- Read and create Panda dataframe from the user uploaded JSON
- Apply filter to df
- Generate html compatible graph to display in webapp 
done! 12/16

CURRENT SHORT TERM GOAL (12/16):

- add to current filter function to allow the following
	- filter by date/time:
		- filter by month
		- filter by shift
- add form to results page. This is where the user can apply more detailed filters
- filter settings:
	- modality
	- date range
	- changeable x axis:
		- day
			- if by day, highlight weekends
		- month
		- quarter?
		- year
	- changeable y axis:
		- number of exams
		- exam order to exam complete time delta
		- exam order to exam  read time delta (ORM to ORU)
		- ratio of total exam completes to total exam order 
	- include stacked bars to view different y values per shift
- send a get request to /filtered via postman
	- in the GET request, send a JSON that includes all the filter settings above
	- /filtered should display the new graph with the GET request's filters applied

MANAGEABLE SHORT TERM GOALS(12/20):

Get these filters working and plotted:
    Periods:
        - day done
        - week done
        - month done
        - year done
    
    modalities: done
        - XR
        - CT
        - MR
        - US
        - NM
done today(12/20)

Next goal:
figure out a clean way to pass data to the beeg filter function. messy rn
Master filter is g2g for now. Refactor as needed in the future. (12/21)

Next goal(12/21):

views.py needs to receive a request body containing filter options. 

- create a test func to run the master_filter
- use postman to send the desired data to a views hook
- return the series axes from master_filter into a json response

CURRENT LONG TERM GOALS:

- Gut instinct tells me storing exam data in a session is dumb and inefficient. Figure out a better way to store user uploaded data
	- Ideas for this:
		- Store csv(maybe convert to JSON before storage? converting to JSON is neccessary for session storage but idk if there is another good reason to convert to JSON. Maybe pandas needs it to be JSON to display as a html graph? probably not) in the web app's server's file system and only store the file path in the django session
		- Store csv in cache using Redis
		- Use csv to create a DB

Temp DB vs Cache for csv data store:

1. Temporary Database Storage

Using a database to store the CSV data allows you to query, filter, and manipulate the data efficiently. Temporary storage means the data might only persist for the user's session or until you explicitly clean it up.
Steps to Implement:

    Create a Model: Define a Django model to represent the structure of your CSV data. If the structure of the CSV varies, you might need to dynamically handle it.

    Example:

from django.db import models

class UploadedData(models.Model):
    session_key = models.CharField(max_length=255)  # To link with the user's session
    row_data = models.JSONField()  # Store each CSV row as JSON
    created_at = models.DateTimeField(auto_now_add=True)

Save Data to the Database: When a user uploads a CSV, parse it into rows and store it as records in the database.

Example:

import pandas as pd
from .models import UploadedData

def store_csv_in_db(csv_file, session_key):
    df = pd.read_csv(csv_file)
    for _, row in df.iterrows():
        UploadedData.objects.create(session_key=session_key, row_data=row.to_dict())

Query Data: When the user applies filters, query the database for matching records and generate the graph.

Clean Up: Periodically delete old records using a cron job or Django management command.

    from datetime import timedelta
    from django.utils.timezone import now
    UploadedData.objects.filter(created_at__lt=now() - timedelta(hours=1)).delete()

2. Caching

Caching is a way to store data temporarily in memory for quick access. Django supports several caching backends, including Redis, Memcached, or file-based caching.
Steps to Implement:

    Set Up the Cache Backend: Install and configure a caching backend. For example, to use Redis:
        Install Redis and the Python library:

pip install redis django-redis

Update your settings.py:

    CACHES = {
        'default': {
            'BACKEND': 'django_redis.cache.RedisCache',
            'LOCATION': 'redis://127.0.0.1:6379/1',
            'OPTIONS': {
                'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            }
        }
    }

Store Data in the Cache: When a CSV file is uploaded, convert it to JSON (or another serializable format) and store it in the cache.

Example:

from django.core.cache import cache
import pandas as pd

def store_csv_in_cache(csv_file, session_key):
    df = pd.read_csv(csv_file)
    cache.set(f"csv_data_{session_key}", df.to_json(), timeout=3600)  # Expires in 1 hour

Retrieve Data from the Cache: When the user applies filters, retrieve the cached data and process it.

Example:

    def get_csv_from_cache(session_key):
        csv_data = cache.get(f"csv_data_{session_key}")
        if csv_data:
            df = pd.read_json(csv_data)
            return df
        return None

    Clean Up Automatically: Caches automatically expire after the specified timeout, so no manual cleanup is needed.

When to Use Which:

    Temporary Database:
    Use this when:
        You need to query/filter data frequently.
        You expect larger datasets that wouldnâ€™t fit well in memory.

    Caching:
    Use this when:
        You want fast, temporary access to data.
        The data size is manageable in memory.
        The dataset doesn't require complex querying (e.g., filtering can be done in Python after retrieving the cached data).

Comparison Table:

Feature				|	Temporary Database				|	Caching
--------------------|-----------------------------------|------------------------------
Speed		    	|	Slower than cache (uses disk)	|	Very fast (uses memory)
Data Size	    	|	Handles large datasets well		|	Limited by memory size
Setup Complexity	|	Moderate (requires DB schema)	|	Easy to moderate (Redis/Memcached setup)
Data Querying		|	Supports complex queries		|	Limited querying (simple retrieval)
Persistence			|	Persists until manually cleared	|	Temporary (auto-expires)


Next step (12/26)

organize url flow

/generate_graph

- get master copy JSON
- format and parse JSON
- set filter
- save graph???
- display in html 